# Xinyi_Portfolio


## [Project 1: Customer Segmentation with Unsupervised KNN Model & RFM Customer Value Analysis](https://github.com/eaco1996c/Customer_Segmentation_KNN_RFM)

This project aims to establish a customers segmentation for telecom consumption. The target is to divide them into 3 stages of different “maintaining value”, high-value customers, medium-value customers and lower-value customers with the RFM(Recency, Frequency and Monetary) evaluation. Based on the "maintaining value", analysis on clusters is applied to profile high value customers in order to establish consumption attracting business methods.

**Project Framework**

![image](https://user-images.githubusercontent.com/38795845/130512127-8806c4ce-cde2-427e-8cb6-0b2786eda649.png)



## [Project 2: Customer Churn Factors Analysis through Binary Classifier Models](https://github.com/eaco1996c/telco_customer_churn)
This project is about to build a binary classifier which can predict the churning customers of the Telco company. Based on a good classifier, explore the feature importance to see which factors are the biggest contributors to a churn customer. On top of that, business insights and suggestions are established and explained.

**Project Framework**

![image](https://user-images.githubusercontent.com/38795845/130504195-953c5312-b8e4-46ca-90ff-862b276a041d.png)




## [Project 3: Big Data Time Series Analysis on Databricks](https://github.com/eaco1996c/metadata_timeseries_Databricks)

This is a metadata project with **~2.65 Million** records and 17 attributes. The dataset is from Kaggle by 
[**Danilo Lessa Bernardineli**](https://danlessa.github.io/), accessed from [Kaggle](https://www.kaggle.com/danlessa/brazilian-bird-observation-metadata-from-wikiaves#).

Many environmental protection data analysis projects have focused on greenhouse gas emissions and the cyclical movement of ocean currents. However, there is another topic to care about, the record and research of ecological species. The data used to record species are generally large-scale data containing essential information. It needs to be processed basically with a scale of millions at one time. Ecological species research pays more attention to overall trends rather than individual details. Therefore, analyzing ecological species change can be an excellent choice to utilize big data.

**Project Framework**

![image](https://user-images.githubusercontent.com/38795845/130500622-82b56d82-cc79-4a65-a62d-e51abf45899f.png)



## [Project 4: OCR Form Recognition with CNN for Image Classification](https://github.com/eaco1996c/OCR_CNN_form_recognization)

This project is a computer vision project. The purpose is to recognize texts from image files with similar patterns. The dataset used is a set of burial records from a cemetery. 
Two solutions of OCR are included. One of them is pytesseract with Python, the other is automate cloud workflow on **[Microsoft Azure](https://azure.microsoft.com/en-us/)**, one of the largest cloud services platforms.

Burial records are important evidence for cemetery service management. They often contain the name of the deceased and the detailed location and date of the burial. Because of the large time span since the burial service started, many dated  records have not been electronicized, and there are handwritten records. This project aims to digitize these records. Digitalization of these records helps maintain them as well as analysis on historical populations. Also, digitized records are more convenient for review and long-term preservation.

**Project Framework**

![image](https://user-images.githubusercontent.com/38795845/130498415-b452e18e-8ffb-4bd4-8c28-8fdac4d41bbc.png)




## [Project 5: NLP TopicModeling with LDA Model Analysis](https://github.com/eaco1996c/NLP_TopicModeling_LDA)

This a NLP course practice project with R. The main purpose is to utilizing Topic Modeling across three well-known novels, _Twenty Thousand Leagues under the Sea_,
_The War of the Worlds_, _Wuthering Heights_. 

First create the document term matrix (DTM). Then use **[LDA](https://medium.datadriveninvestor.com/nlp-with-lda-analyzing-topics-in-the-enron-email-dataset-20326b7ae36f)**(Latent Dirichlet Allocation) to make a 3-topic model. We are going to judge which two books are more closely related. 
- Separate the document name into title and chapter using the separate function and ggplot2 to visualize the per-document-per-topic probability for each topic
- Develop the “consensus” topic for each book
- Use the augment function to develop the words assignment for each topic
- Develop the confusion matrix for all the topics

**Project Framework**

![image](https://user-images.githubusercontent.com/38795845/130510601-8a63de43-eba1-41f7-b1f1-dbdefb9f5d92.png)
